{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Building Input Functions with tf.contrib.learn <center>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Custom Input Pipelines with input_fn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a neural network using tf.contrib.learn, it's possible to pass your feature and target data directly into your fit, evaluate, or predict operations. This approach works well when little to no manipulation of source data is required. But in cases where more feature engineering is needed, tf.contrib.learn supports using a custom input function (input_fn) to encapsulate the logic for preprocessing and piping data into your models.\n",
    "\n",
    "The following code illustrates the basic skeleton for an input function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    # Preprocess your data here...\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the input function contains the specific logic for preprocessing your input data, such as scrubbing out bad examples or feature scaling.\n",
    "\n",
    "Input functions must return the following two values containing the final feature and label data to be fed into your model (as shown in the above code skeleton):\n",
    "\n",
    "    -feature_cols: a dict containing key/value pairs that map feature column names to Tensors (or SparseTensors)    containing the corresponding feature data.\n",
    "    -labels: a Tensor containing your label (target) values: the values your model aims to predict.\n",
    "\n",
    "**If your feature/label data is stored in pandas dataframes or numpy arrays, you'll need to convert it to Tensors before returning it from your input_fn.**\n",
    "\n",
    "For continuous data, you can create and populate a Tensor using tf.constant:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_data = [1, 2.4, 0, 9.9, 3, 120]\n",
    "feature_tensor = tf.constant(feature_column_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sparse, categorical data (data where the majority of values are 0), you'll instead want to populate a SparseTensor, which is instantiated with three arguments:\n",
    "\n",
    "    -dense_shape -> The shape of the tensor. Takes a list indicating the number of elements in each dimension. For example, dense_shape=[3,6] specifies a two-dimensional 3x6 tensor, dense_shape=[2,3,4] specifies a three-dimensional 2x3x4 tensor, and dense_shape=[9] specifies a one-dimensional tensor with 9 elements.\n",
    "    -indices -> The indices of the elements in your tensor that contain nonzero values. Takes a list of terms, where each term is itself a list containing the index of a nonzero element. (Elements are zero-indexed—i.e., [0,0] is the index value for the element in the first column of the first row in a two-dimensional tensor.) For example, indices=[[1,3], [2,4]] specifies that the elements with indexes of [1,3] and [2,4] have nonzero values.\n",
    "    -values -> A one-dimensional tensor of values. Term i in values corresponds to term i in indices and specifies its value. For example, given indices=[[1,3], [2,4]], the parameter values=[18, 3.6] specifies that element [1,3] of the tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_tensor = tf.SparseTensor(indices=[[0,1], [2,4]],\n",
    "                                values=[6, 0.5],\n",
    "                                dense_shape=[3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Passing input_fn Data to Your Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed data to your model for training, you simply pass the input function you've created to your fit operation as the value of the input_fn parameter, e.g.:\n",
    "\n",
    "**classifier.fit(input_fn=my_input_fn, steps=2000)**\n",
    "\n",
    "Note that the input_fn is responsible for supplying both feature and label data to the model, and replaces both the x and y parameters in fit. If you supply an input_fn value to fit that is not None in conjunction with either an x or y parameter that is not None, it will result in a ValueError.\n",
    "\n",
    "Also note that the input_fn parameter must receive a function object (i.e., input_fn=my_input_fn), not the return value of a function call (input_fn=my_input_fn()). This means that if you try to pass parameters to the input function in your fit call, as in the following code, it will result in a **TypeError:**\n",
    "\n",
    "**classifier.fit(input_fn=my_input_fn(training_set), steps=2000)**\n",
    "\n",
    "However, if you'd like to be able to parameterize your input function, there are other methods for doing so. You can employ a wrapper function that takes no arguments as your input_fn and use it to invoke your input function with the desired parameters. For example:\n",
    "\n",
    "def my_input_function_training_set():\n",
    "  return my_input_function(training_set)\n",
    "\n",
    "classifier.fit(input_fn=my_input_fn_training_set, steps=2000)\n",
    "\n",
    "Alternatively, you can use Python's functools.partial function to construct a new function object with all parameter values fixed:\n",
    "\n",
    "classifier.fit(input_fn=functools.partial(my_input_function,\n",
    "                                          data_set=training_set), steps=2000)\n",
    "                                          \n",
    "**A third option is to wrap your input_fn invocation in a lambda and pass it to the input_fn parameter:**\n",
    "\n",
    "**classifier.fit(input_fn=lambda: my_input_fn(training_set), steps=2000)**\n",
    "\n",
    "**One big advantage of architecting your input pipeline as shown above—to accept a parameter for data set—is that you can pass the same input_fn to evaluate and predict operations by just changing the data set argument, e.g.:**\n",
    "\n",
    "**classifier.evaluate(input_fn=lambda: my_input_fn(test_set), steps=2000)**\n",
    "\n",
    "This approach enhances code maintainability: no need to capture x and y values in separate variables (e.g., x_train, x_test, y_train, y_test) for each type of operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A Neural Network Model for Boston House Values\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "            \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\"\n",
    "path = \"/home/antonio/Desktop/TensorFlow_Tutorials/Data/BostonHouseValues/\"\n",
    "\n",
    "training_set = pd.read_csv(path + \"boston_train.csv\", skipinitialspace=True,\n",
    "                           skiprows=1, names=COLUMNS)\n",
    "test_set = pd.read_csv(path + \"boston_test.csv\", skipinitialspace=True,\n",
    "                       skiprows=1, names=COLUMNS)\n",
    "prediction_set = pd.read_csv(path + \"boston_predict.csv\", skipinitialspace=True,\n",
    "                             skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining FeatureColumns and Creating the Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a list of FeatureColumns for the input data, which formally specify the set of features to use for training. Because all features in the housing data set contain continuous values, you can create their FeatureColumns using the tf.contrib.layers.real_valued_column() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [tf.contrib.layers.real_valued_column(k)\n",
    "                  for k in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate a DNNRegressor for the neural network regression model. You'll need to provide two arguments here: hidden_units, a hyperparameter specifying the number of nodes in each hidden layer (here, two hidden layers with 10 nodes each), and feature_columns, containing the list of FeatureColumns you just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_master': '', '_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efeabc7ffd0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_is_chief': True, '_evaluation_master': '', '_tf_random_seed': None}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                          hidden_units=[10, 10],\n",
    "                                          model_dir=\"/tmp/boston_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass input data into the regressor, create an input function, which will accept a pandas Dataframe and return feature column and label values as Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values)\n",
    "                  for k in FEATURES}\n",
    "    labels = tf.constant(data_set[LABEL].values)\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/antonio/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/boston_model/model.ckpt.\n",
      "INFO:tensorflow:step = 5001, loss = 45.0254\n",
      "INFO:tensorflow:global_step/sec: 1157.93\n",
      "INFO:tensorflow:step = 5101, loss = 37.8412\n",
      "INFO:tensorflow:global_step/sec: 1163.11\n",
      "INFO:tensorflow:step = 5201, loss = 37.5019\n",
      "INFO:tensorflow:global_step/sec: 1113.11\n",
      "INFO:tensorflow:step = 5301, loss = 37.3055\n",
      "INFO:tensorflow:global_step/sec: 1033.45\n",
      "INFO:tensorflow:step = 5401, loss = 37.1244\n",
      "INFO:tensorflow:global_step/sec: 1302.18\n",
      "INFO:tensorflow:step = 5501, loss = 36.9966\n",
      "INFO:tensorflow:global_step/sec: 1118.48\n",
      "INFO:tensorflow:step = 5601, loss = 47.816\n",
      "INFO:tensorflow:global_step/sec: 1043.57\n",
      "INFO:tensorflow:step = 5701, loss = 36.7595\n",
      "INFO:tensorflow:global_step/sec: 1150.22\n",
      "INFO:tensorflow:step = 5801, loss = 36.5627\n",
      "INFO:tensorflow:global_step/sec: 1127.83\n",
      "INFO:tensorflow:step = 5901, loss = 36.4381\n",
      "INFO:tensorflow:global_step/sec: 1094.06\n",
      "INFO:tensorflow:step = 6001, loss = 36.323\n",
      "INFO:tensorflow:global_step/sec: 577.546\n",
      "INFO:tensorflow:step = 6101, loss = 36.2171\n",
      "INFO:tensorflow:global_step/sec: 490.864\n",
      "INFO:tensorflow:step = 6201, loss = 36.2005\n",
      "INFO:tensorflow:global_step/sec: 999.601\n",
      "INFO:tensorflow:step = 6301, loss = 45.2208\n",
      "INFO:tensorflow:global_step/sec: 1261.38\n",
      "INFO:tensorflow:step = 6401, loss = 36.0389\n",
      "INFO:tensorflow:global_step/sec: 988.64\n",
      "INFO:tensorflow:step = 6501, loss = 35.8884\n",
      "INFO:tensorflow:global_step/sec: 513.376\n",
      "INFO:tensorflow:step = 6601, loss = 35.814\n",
      "INFO:tensorflow:global_step/sec: 731.794\n",
      "INFO:tensorflow:step = 6701, loss = 35.7457\n",
      "INFO:tensorflow:global_step/sec: 1180.43\n",
      "INFO:tensorflow:step = 6801, loss = 35.6822\n",
      "INFO:tensorflow:global_step/sec: 1305.34\n",
      "INFO:tensorflow:step = 6901, loss = 35.6235\n",
      "INFO:tensorflow:global_step/sec: 1048.1\n",
      "INFO:tensorflow:step = 7001, loss = 35.5785\n",
      "INFO:tensorflow:global_step/sec: 1035.21\n",
      "INFO:tensorflow:step = 7101, loss = 36.6848\n",
      "INFO:tensorflow:global_step/sec: 1210.97\n",
      "INFO:tensorflow:step = 7201, loss = 37.3838\n",
      "INFO:tensorflow:global_step/sec: 1205.81\n",
      "INFO:tensorflow:step = 7301, loss = 35.4575\n",
      "INFO:tensorflow:global_step/sec: 1218.73\n",
      "INFO:tensorflow:step = 7401, loss = 35.4004\n",
      "INFO:tensorflow:global_step/sec: 1084.49\n",
      "INFO:tensorflow:step = 7501, loss = 35.3615\n",
      "INFO:tensorflow:global_step/sec: 1070.57\n",
      "INFO:tensorflow:step = 7601, loss = 35.3256\n",
      "INFO:tensorflow:global_step/sec: 1104.05\n",
      "INFO:tensorflow:step = 7701, loss = 35.2922\n",
      "INFO:tensorflow:global_step/sec: 1139.9\n",
      "INFO:tensorflow:step = 7801, loss = 35.261\n",
      "INFO:tensorflow:global_step/sec: 1115.23\n",
      "INFO:tensorflow:step = 7901, loss = 35.232\n",
      "INFO:tensorflow:global_step/sec: 1224.45\n",
      "INFO:tensorflow:step = 8001, loss = 35.2054\n",
      "INFO:tensorflow:global_step/sec: 1168.61\n",
      "INFO:tensorflow:step = 8101, loss = 35.1978\n",
      "INFO:tensorflow:global_step/sec: 1181.03\n",
      "INFO:tensorflow:step = 8201, loss = 36.1916\n",
      "INFO:tensorflow:global_step/sec: 1165.41\n",
      "INFO:tensorflow:step = 8301, loss = 37.3899\n",
      "INFO:tensorflow:global_step/sec: 1016.59\n",
      "INFO:tensorflow:step = 8401, loss = 35.1627\n",
      "INFO:tensorflow:global_step/sec: 1103.18\n",
      "INFO:tensorflow:step = 8501, loss = 35.102\n",
      "INFO:tensorflow:global_step/sec: 1276.55\n",
      "INFO:tensorflow:step = 8601, loss = 35.0824\n",
      "INFO:tensorflow:global_step/sec: 1030.27\n",
      "INFO:tensorflow:step = 8701, loss = 35.0651\n",
      "INFO:tensorflow:global_step/sec: 1002.75\n",
      "INFO:tensorflow:step = 8801, loss = 35.0488\n",
      "INFO:tensorflow:global_step/sec: 1056.67\n",
      "INFO:tensorflow:step = 8901, loss = 35.0336\n",
      "INFO:tensorflow:global_step/sec: 1179.76\n",
      "INFO:tensorflow:step = 9001, loss = 35.0192\n",
      "INFO:tensorflow:global_step/sec: 1143.26\n",
      "INFO:tensorflow:step = 9101, loss = 35.0057\n",
      "INFO:tensorflow:global_step/sec: 1232.8\n",
      "INFO:tensorflow:step = 9201, loss = 34.993\n",
      "INFO:tensorflow:global_step/sec: 1067.27\n",
      "INFO:tensorflow:step = 9301, loss = 34.981\n",
      "INFO:tensorflow:global_step/sec: 989.111\n",
      "INFO:tensorflow:step = 9401, loss = 34.9697\n",
      "INFO:tensorflow:global_step/sec: 736.651\n",
      "INFO:tensorflow:step = 9501, loss = 34.9597\n",
      "INFO:tensorflow:global_step/sec: 521.95\n",
      "INFO:tensorflow:step = 9601, loss = 34.9622\n",
      "INFO:tensorflow:global_step/sec: 631.718\n",
      "INFO:tensorflow:step = 9701, loss = 35.2522\n",
      "INFO:tensorflow:global_step/sec: 1127.86\n",
      "INFO:tensorflow:step = 9801, loss = 37.7413\n",
      "INFO:tensorflow:global_step/sec: 1022.94\n",
      "INFO:tensorflow:step = 9901, loss = 35.2455\n",
      "INFO:tensorflow:global_step/sec: 1248.66\n",
      "INFO:tensorflow:step = 10001, loss = 34.93\n",
      "INFO:tensorflow:global_step/sec: 1137.29\n",
      "INFO:tensorflow:step = 10101, loss = 34.9089\n",
      "INFO:tensorflow:global_step/sec: 1024.1\n",
      "INFO:tensorflow:step = 10201, loss = 34.9006\n",
      "INFO:tensorflow:global_step/sec: 1122.19\n",
      "INFO:tensorflow:step = 10301, loss = 34.8932\n",
      "INFO:tensorflow:global_step/sec: 1075.08\n",
      "INFO:tensorflow:step = 10401, loss = 34.8863\n",
      "INFO:tensorflow:global_step/sec: 1072.95\n",
      "INFO:tensorflow:step = 10501, loss = 34.8797\n",
      "INFO:tensorflow:global_step/sec: 1218.45\n",
      "INFO:tensorflow:step = 10601, loss = 34.8733\n",
      "INFO:tensorflow:global_step/sec: 1096.95\n",
      "INFO:tensorflow:step = 10701, loss = 34.8672\n",
      "INFO:tensorflow:global_step/sec: 981.477\n",
      "INFO:tensorflow:step = 10801, loss = 34.8613\n",
      "INFO:tensorflow:global_step/sec: 1228.79\n",
      "INFO:tensorflow:step = 10901, loss = 34.8557\n",
      "INFO:tensorflow:global_step/sec: 1042.72\n",
      "INFO:tensorflow:step = 11001, loss = 34.8502\n",
      "INFO:tensorflow:global_step/sec: 1026.82\n",
      "INFO:tensorflow:step = 11101, loss = 34.8449\n",
      "INFO:tensorflow:global_step/sec: 977.32\n",
      "INFO:tensorflow:step = 11201, loss = 34.8398\n",
      "INFO:tensorflow:global_step/sec: 1164.36\n",
      "INFO:tensorflow:step = 11301, loss = 34.8349\n",
      "INFO:tensorflow:global_step/sec: 1036.16\n",
      "INFO:tensorflow:step = 11401, loss = 34.8302\n",
      "INFO:tensorflow:global_step/sec: 987.79\n",
      "INFO:tensorflow:step = 11501, loss = 34.8255\n",
      "INFO:tensorflow:global_step/sec: 1285.1\n",
      "INFO:tensorflow:step = 11601, loss = 34.821\n",
      "INFO:tensorflow:global_step/sec: 909.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 11701, loss = 34.8166\n",
      "INFO:tensorflow:global_step/sec: 1145.26\n",
      "INFO:tensorflow:step = 11801, loss = 34.8127\n",
      "INFO:tensorflow:global_step/sec: 1295.43\n",
      "INFO:tensorflow:step = 11901, loss = 34.8108\n",
      "INFO:tensorflow:global_step/sec: 1166.51\n",
      "INFO:tensorflow:step = 12001, loss = 34.8267\n",
      "INFO:tensorflow:global_step/sec: 1023.19\n",
      "INFO:tensorflow:step = 12101, loss = 35.0115\n",
      "INFO:tensorflow:global_step/sec: 1225.17\n",
      "INFO:tensorflow:step = 12201, loss = 36.7807\n",
      "INFO:tensorflow:global_step/sec: 1244.67\n",
      "INFO:tensorflow:step = 12301, loss = 35.1419\n",
      "INFO:tensorflow:global_step/sec: 1126.57\n",
      "INFO:tensorflow:step = 12401, loss = 34.8101\n",
      "INFO:tensorflow:global_step/sec: 1166.41\n",
      "INFO:tensorflow:step = 12501, loss = 34.7874\n",
      "INFO:tensorflow:global_step/sec: 1037.44\n",
      "INFO:tensorflow:step = 12601, loss = 34.7826\n",
      "INFO:tensorflow:global_step/sec: 1133.68\n",
      "INFO:tensorflow:step = 12701, loss = 34.7789\n",
      "INFO:tensorflow:global_step/sec: 1172.94\n",
      "INFO:tensorflow:step = 12801, loss = 34.7754\n",
      "INFO:tensorflow:global_step/sec: 947.707\n",
      "INFO:tensorflow:step = 12901, loss = 34.7719\n",
      "INFO:tensorflow:global_step/sec: 1246.19\n",
      "INFO:tensorflow:step = 13001, loss = 34.7685\n",
      "INFO:tensorflow:global_step/sec: 1277\n",
      "INFO:tensorflow:step = 13101, loss = 34.7651\n",
      "INFO:tensorflow:global_step/sec: 1210.99\n",
      "INFO:tensorflow:step = 13201, loss = 34.7618\n",
      "INFO:tensorflow:global_step/sec: 803.89\n",
      "INFO:tensorflow:step = 13301, loss = 34.7585\n",
      "INFO:tensorflow:global_step/sec: 614.962\n",
      "INFO:tensorflow:step = 13401, loss = 34.7552\n",
      "INFO:tensorflow:global_step/sec: 876.045\n",
      "INFO:tensorflow:step = 13501, loss = 34.752\n",
      "INFO:tensorflow:global_step/sec: 1028.02\n",
      "INFO:tensorflow:step = 13601, loss = 34.7488\n",
      "INFO:tensorflow:global_step/sec: 952.837\n",
      "INFO:tensorflow:step = 13701, loss = 34.7457\n",
      "INFO:tensorflow:global_step/sec: 770.022\n",
      "INFO:tensorflow:step = 13801, loss = 34.7436\n",
      "INFO:tensorflow:global_step/sec: 923.626\n",
      "INFO:tensorflow:step = 13901, loss = 34.7416\n",
      "INFO:tensorflow:global_step/sec: 1111.49\n",
      "INFO:tensorflow:step = 14001, loss = 34.7396\n",
      "INFO:tensorflow:global_step/sec: 1106.1\n",
      "INFO:tensorflow:step = 14101, loss = 34.7386\n",
      "INFO:tensorflow:global_step/sec: 810.783\n",
      "INFO:tensorflow:step = 14201, loss = 34.7368\n",
      "INFO:tensorflow:global_step/sec: 800.597\n",
      "INFO:tensorflow:step = 14301, loss = 34.7353\n",
      "INFO:tensorflow:global_step/sec: 951.316\n",
      "INFO:tensorflow:step = 14401, loss = 34.7339\n",
      "INFO:tensorflow:global_step/sec: 1197.15\n",
      "INFO:tensorflow:step = 14501, loss = 34.7328\n",
      "INFO:tensorflow:global_step/sec: 1028.11\n",
      "INFO:tensorflow:step = 14601, loss = 34.7339\n",
      "INFO:tensorflow:global_step/sec: 619.664\n",
      "INFO:tensorflow:step = 14701, loss = 34.7337\n",
      "INFO:tensorflow:global_step/sec: 956.898\n",
      "INFO:tensorflow:step = 14801, loss = 34.7337\n",
      "INFO:tensorflow:global_step/sec: 1004.4\n",
      "INFO:tensorflow:step = 14901, loss = 34.7365\n",
      "INFO:tensorflow:global_step/sec: 972.317\n",
      "INFO:tensorflow:step = 15001, loss = 34.7396\n",
      "INFO:tensorflow:global_step/sec: 1089.02\n",
      "INFO:tensorflow:step = 15101, loss = 34.7399\n",
      "INFO:tensorflow:global_step/sec: 1228.01\n",
      "INFO:tensorflow:step = 15201, loss = 34.7394\n",
      "INFO:tensorflow:global_step/sec: 933.576\n",
      "INFO:tensorflow:step = 15301, loss = 34.7411\n",
      "INFO:tensorflow:global_step/sec: 1041.99\n",
      "INFO:tensorflow:step = 15401, loss = 34.7387\n",
      "INFO:tensorflow:global_step/sec: 945.376\n",
      "INFO:tensorflow:step = 15501, loss = 34.7321\n",
      "INFO:tensorflow:global_step/sec: 1270.9\n",
      "INFO:tensorflow:step = 15601, loss = 34.7281\n",
      "INFO:tensorflow:global_step/sec: 1059.21\n",
      "INFO:tensorflow:step = 15701, loss = 34.7239\n",
      "INFO:tensorflow:global_step/sec: 963.256\n",
      "INFO:tensorflow:step = 15801, loss = 34.7171\n",
      "INFO:tensorflow:global_step/sec: 1060.52\n",
      "INFO:tensorflow:step = 15901, loss = 34.7132\n",
      "INFO:tensorflow:global_step/sec: 1167.63\n",
      "INFO:tensorflow:step = 16001, loss = 34.7071\n",
      "INFO:tensorflow:global_step/sec: 1027.13\n",
      "INFO:tensorflow:step = 16101, loss = 34.7042\n",
      "INFO:tensorflow:global_step/sec: 1050.47\n",
      "INFO:tensorflow:step = 16201, loss = 34.6989\n",
      "INFO:tensorflow:global_step/sec: 858.064\n",
      "INFO:tensorflow:step = 16301, loss = 34.6966\n",
      "INFO:tensorflow:global_step/sec: 467.458\n",
      "INFO:tensorflow:step = 16401, loss = 34.6919\n",
      "INFO:tensorflow:global_step/sec: 774.527\n",
      "INFO:tensorflow:step = 16501, loss = 34.6899\n",
      "INFO:tensorflow:global_step/sec: 1051.86\n",
      "INFO:tensorflow:step = 16601, loss = 34.6879\n",
      "INFO:tensorflow:global_step/sec: 1093.36\n",
      "INFO:tensorflow:step = 16701, loss = 34.686\n",
      "INFO:tensorflow:global_step/sec: 1061.26\n",
      "INFO:tensorflow:step = 16801, loss = 34.6817\n",
      "INFO:tensorflow:global_step/sec: 913.002\n",
      "INFO:tensorflow:step = 16901, loss = 34.6799\n",
      "INFO:tensorflow:global_step/sec: 1033.04\n",
      "INFO:tensorflow:step = 17001, loss = 34.6781\n",
      "INFO:tensorflow:global_step/sec: 1244.76\n",
      "INFO:tensorflow:step = 17101, loss = 34.6738\n",
      "INFO:tensorflow:global_step/sec: 1126.34\n",
      "INFO:tensorflow:step = 17201, loss = 34.6719\n",
      "INFO:tensorflow:global_step/sec: 1025.58\n",
      "INFO:tensorflow:step = 17301, loss = 34.6701\n",
      "INFO:tensorflow:global_step/sec: 1047.65\n",
      "INFO:tensorflow:step = 17401, loss = 34.6658\n",
      "INFO:tensorflow:global_step/sec: 1014.93\n",
      "INFO:tensorflow:step = 17501, loss = 34.6639\n",
      "INFO:tensorflow:global_step/sec: 1004.2\n",
      "INFO:tensorflow:step = 17601, loss = 34.6621\n",
      "INFO:tensorflow:global_step/sec: 1031.17\n",
      "INFO:tensorflow:step = 17701, loss = 34.6577\n",
      "INFO:tensorflow:global_step/sec: 1166.37\n",
      "INFO:tensorflow:step = 17801, loss = 34.6558\n",
      "INFO:tensorflow:global_step/sec: 1032.61\n",
      "INFO:tensorflow:step = 17901, loss = 34.654\n",
      "INFO:tensorflow:global_step/sec: 1259.38\n",
      "INFO:tensorflow:step = 18001, loss = 34.6498\n",
      "INFO:tensorflow:global_step/sec: 1015.52\n",
      "INFO:tensorflow:step = 18101, loss = 34.648\n",
      "INFO:tensorflow:global_step/sec: 1261.49\n",
      "INFO:tensorflow:step = 18201, loss = 34.6438\n",
      "INFO:tensorflow:global_step/sec: 1039.89\n",
      "INFO:tensorflow:step = 18301, loss = 34.6421\n",
      "INFO:tensorflow:global_step/sec: 1216.35\n",
      "INFO:tensorflow:step = 18401, loss = 34.6381\n",
      "INFO:tensorflow:global_step/sec: 1049.48\n",
      "INFO:tensorflow:step = 18501, loss = 34.6363\n",
      "INFO:tensorflow:global_step/sec: 813.236\n",
      "INFO:tensorflow:step = 18601, loss = 34.6348\n",
      "INFO:tensorflow:global_step/sec: 585.079\n",
      "INFO:tensorflow:step = 18701, loss = 34.6309\n",
      "INFO:tensorflow:global_step/sec: 741.955\n",
      "INFO:tensorflow:step = 18801, loss = 34.6294\n",
      "INFO:tensorflow:global_step/sec: 1074.54\n",
      "INFO:tensorflow:step = 18901, loss = 34.6255\n",
      "INFO:tensorflow:global_step/sec: 1109.91\n",
      "INFO:tensorflow:step = 19001, loss = 34.624\n",
      "INFO:tensorflow:global_step/sec: 1171.19\n",
      "INFO:tensorflow:step = 19101, loss = 34.6201\n",
      "INFO:tensorflow:global_step/sec: 1135.18\n",
      "INFO:tensorflow:step = 19201, loss = 34.6186\n",
      "INFO:tensorflow:global_step/sec: 692.294\n",
      "INFO:tensorflow:step = 19301, loss = 34.6149\n",
      "INFO:tensorflow:global_step/sec: 730.616\n",
      "INFO:tensorflow:step = 19401, loss = 34.6135\n",
      "INFO:tensorflow:global_step/sec: 885.474\n",
      "INFO:tensorflow:step = 19501, loss = 34.6099\n",
      "INFO:tensorflow:global_step/sec: 1229.98\n",
      "INFO:tensorflow:step = 19601, loss = 34.6086\n",
      "INFO:tensorflow:global_step/sec: 1075.18\n",
      "INFO:tensorflow:step = 19701, loss = 34.6049\n",
      "INFO:tensorflow:global_step/sec: 1081.53\n",
      "INFO:tensorflow:step = 19801, loss = 34.6036\n",
      "INFO:tensorflow:global_step/sec: 1094.18\n",
      "INFO:tensorflow:step = 19901, loss = 34.6\n",
      "INFO:tensorflow:global_step/sec: 897.561\n",
      "INFO:tensorflow:step = 20001, loss = 34.5988\n",
      "INFO:tensorflow:global_step/sec: 652.357\n",
      "INFO:tensorflow:step = 20101, loss = 34.5953\n",
      "INFO:tensorflow:global_step/sec: 828.899\n",
      "INFO:tensorflow:step = 20201, loss = 34.5941\n",
      "INFO:tensorflow:global_step/sec: 1204.19\n",
      "INFO:tensorflow:step = 20301, loss = 34.5905\n",
      "INFO:tensorflow:global_step/sec: 924.147\n",
      "INFO:tensorflow:step = 20401, loss = 34.5893\n",
      "INFO:tensorflow:global_step/sec: 1288.96\n",
      "INFO:tensorflow:step = 20501, loss = 34.5858\n",
      "INFO:tensorflow:global_step/sec: 1145.4\n",
      "INFO:tensorflow:step = 20601, loss = 34.5848\n",
      "INFO:tensorflow:global_step/sec: 1242.57\n",
      "INFO:tensorflow:step = 20701, loss = 34.5814\n",
      "INFO:tensorflow:global_step/sec: 953.886\n",
      "INFO:tensorflow:step = 20801, loss = 34.5781\n",
      "INFO:tensorflow:global_step/sec: 698.011\n",
      "INFO:tensorflow:step = 20901, loss = 34.577\n",
      "INFO:tensorflow:global_step/sec: 918.456\n",
      "INFO:tensorflow:step = 21001, loss = 34.5738\n",
      "INFO:tensorflow:global_step/sec: 1185.39\n",
      "INFO:tensorflow:step = 21101, loss = 34.5728\n",
      "INFO:tensorflow:global_step/sec: 1140.02\n",
      "INFO:tensorflow:step = 21201, loss = 34.5695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1070.56\n",
      "INFO:tensorflow:step = 21301, loss = 34.5663\n",
      "INFO:tensorflow:global_step/sec: 1124.48\n",
      "INFO:tensorflow:step = 21401, loss = 34.5653\n",
      "INFO:tensorflow:global_step/sec: 1309.5\n",
      "INFO:tensorflow:step = 21501, loss = 34.5622\n",
      "INFO:tensorflow:global_step/sec: 1297.53\n",
      "INFO:tensorflow:step = 21601, loss = 34.5591\n",
      "INFO:tensorflow:global_step/sec: 1286\n",
      "INFO:tensorflow:step = 21701, loss = 34.5583\n",
      "INFO:tensorflow:global_step/sec: 654.985\n",
      "INFO:tensorflow:step = 21801, loss = 34.5552\n",
      "INFO:tensorflow:global_step/sec: 785.68\n",
      "INFO:tensorflow:step = 21901, loss = 34.5545\n",
      "INFO:tensorflow:global_step/sec: 927.273\n",
      "INFO:tensorflow:step = 22001, loss = 34.5514\n",
      "INFO:tensorflow:global_step/sec: 1113.81\n",
      "INFO:tensorflow:step = 22101, loss = 34.5484\n",
      "INFO:tensorflow:global_step/sec: 1184.76\n",
      "INFO:tensorflow:step = 22201, loss = 34.5453\n",
      "INFO:tensorflow:global_step/sec: 1348.93\n",
      "INFO:tensorflow:step = 22301, loss = 34.5446\n",
      "INFO:tensorflow:global_step/sec: 1202.65\n",
      "INFO:tensorflow:step = 22401, loss = 34.5416\n",
      "INFO:tensorflow:global_step/sec: 845.145\n",
      "INFO:tensorflow:step = 22501, loss = 34.5387\n",
      "INFO:tensorflow:global_step/sec: 664.227\n",
      "INFO:tensorflow:step = 22601, loss = 34.5381\n",
      "INFO:tensorflow:global_step/sec: 682.045\n",
      "INFO:tensorflow:step = 22701, loss = 34.5353\n",
      "INFO:tensorflow:global_step/sec: 686.114\n",
      "INFO:tensorflow:step = 22801, loss = 34.5324\n",
      "INFO:tensorflow:global_step/sec: 770.284\n",
      "INFO:tensorflow:step = 22901, loss = 34.5295\n",
      "INFO:tensorflow:global_step/sec: 701.681\n",
      "INFO:tensorflow:step = 23001, loss = 34.5291\n",
      "INFO:tensorflow:global_step/sec: 608.14\n",
      "INFO:tensorflow:step = 23101, loss = 34.5262\n",
      "INFO:tensorflow:global_step/sec: 779.399\n",
      "INFO:tensorflow:step = 23201, loss = 34.5234\n",
      "INFO:tensorflow:global_step/sec: 938.363\n",
      "INFO:tensorflow:step = 23301, loss = 34.5231\n",
      "INFO:tensorflow:global_step/sec: 1232.48\n",
      "INFO:tensorflow:step = 23401, loss = 34.5203\n",
      "INFO:tensorflow:global_step/sec: 1259.59\n",
      "INFO:tensorflow:step = 23501, loss = 34.5177\n",
      "INFO:tensorflow:global_step/sec: 1079.7\n",
      "INFO:tensorflow:step = 23601, loss = 34.515\n",
      "INFO:tensorflow:global_step/sec: 1091.43\n",
      "INFO:tensorflow:step = 23701, loss = 34.5122\n",
      "INFO:tensorflow:global_step/sec: 1277.71\n",
      "INFO:tensorflow:step = 23801, loss = 34.512\n",
      "INFO:tensorflow:global_step/sec: 1181.11\n",
      "INFO:tensorflow:step = 23901, loss = 34.5094\n",
      "INFO:tensorflow:global_step/sec: 677.828\n",
      "INFO:tensorflow:step = 24001, loss = 34.5068\n",
      "INFO:tensorflow:global_step/sec: 730.564\n",
      "INFO:tensorflow:step = 24101, loss = 34.5042\n",
      "INFO:tensorflow:global_step/sec: 722.144\n",
      "INFO:tensorflow:step = 24201, loss = 34.5017\n",
      "INFO:tensorflow:global_step/sec: 1246.92\n",
      "INFO:tensorflow:step = 24301, loss = 34.4992\n",
      "INFO:tensorflow:global_step/sec: 1102.18\n",
      "INFO:tensorflow:step = 24401, loss = 34.4991\n",
      "INFO:tensorflow:global_step/sec: 723.726\n",
      "INFO:tensorflow:step = 24501, loss = 34.4964\n",
      "INFO:tensorflow:global_step/sec: 727.936\n",
      "INFO:tensorflow:step = 24601, loss = 34.4939\n",
      "INFO:tensorflow:global_step/sec: 1072.31\n",
      "INFO:tensorflow:step = 24701, loss = 34.4915\n",
      "INFO:tensorflow:global_step/sec: 1106.43\n",
      "INFO:tensorflow:step = 24801, loss = 34.4892\n",
      "INFO:tensorflow:global_step/sec: 1155.57\n",
      "INFO:tensorflow:step = 24901, loss = 34.4868\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/boston_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 34.4844.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None, 'hidden_units': [10, 10], 'optimizer': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7efeaed6d8d0>, 'activation_fn': <function relu at 0x7efeaf27d9d8>, 'feature_columns': (_RealValuedColumn(column_name='crim', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='zn', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='indus', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='nox', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='rm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dis', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='tax', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='ptratio', dimension=1, default_value=None, dtype=tf.float32, normalizer=None))})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/antonio/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-04-06-21:50:50\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-04-06-21:50:50\n",
      "INFO:tensorflow:Saving dict for global step 25000: global_step = 25000, loss = 17.1096\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "ev = regressor.evaluate(input_fn=lambda: input_fn(test_set), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17.109570\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "Predictions: [34.484119, 19.360765, 23.620646, 34.523815, 13.196375, 19.57361]\n"
     ]
    }
   ],
   "source": [
    "y = regressor.predict(input_fn=lambda: input_fn(prediction_set))\n",
    "# .predict() returns an iterator; convert to a list and print predictions\n",
    "predictions = list(itertools.islice(y, 6))\n",
    "print (\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
