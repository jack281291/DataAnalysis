{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Getting started with Tensorflow </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Computational Graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output. One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally. We can create two floating point Tensors node1 and node2 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that printing the nodes does not output the values 3.0 and 4.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime.\n",
    "\n",
    "The following code creates a Session object and then invokes its run method to run enough of the computational graph to evaluate node1 and node2. By running the computational graph in a session as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 4.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "node1, node2 = sess.run([node1, node2])\n",
    "print(node1, node2)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, this graph is not especially interesting because it always produces a constant result. A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = tf.subtract(a, b)\n",
    "sess = tf.Session()\n",
    "c = sess.run(c, feed_dict={a: 5.0, b: 1.4})\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(initial_value=[0.1], dtype=tf.float32)\n",
    "b = tf.Variable(initial_value=[1], dtype=tf.float32)\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "y_hat = W * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants are initialized when you call tf.constant, and their value can never change. By contrast, variables are not initialized when you call tf.Variable. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.10000002,  1.20000005,  1.29999995,  1.39999998], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y_hat, feed_dict={X: [1,2,3,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2249999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss, feed_dict={X: [1.0,2.0,3.0,4.0], y:[1.0,2.0,4.0,5.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.2], dtype=float32), array([ 1.20000005], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixW = tf.assign(W, [0.2])\n",
    "fixb = tf.assign(b, [1.2])\n",
    "sess.run([fixW, fixb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.2], dtype=float32), array([ 1.20000005], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "tf.train API\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides optimizers that slowly change each variable in order to minimize the loss function. The simplest optimizer is gradient descent. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. In general, computing symbolic derivatives manually is tedious and error-prone. Consequently, TensorFlow can automatically produce derivatives given only a description of the model using the function tf.gradients. For simplicity, optimizers typically do this for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45999998] [ 1.28600001]\n",
      "[ 0.6767] [ 1.35728002]\n",
      "[ 0.85733098] [ 1.41629946]\n",
      "[ 1.00791633] [ 1.46510696]\n",
      "[ 1.13347352] [ 1.505409]\n",
      "[ 1.23818207] [ 1.53862715]\n",
      "[ 1.32552338] [ 1.56594551]\n",
      "[ 1.39839756] [ 1.58835042]\n",
      "[ 1.45922041] [ 1.60666358]\n",
      "[ 1.51000416] [ 1.62156928]\n",
      "[ 1.55242503] [ 1.63363767]\n",
      "[ 1.58787942] [ 1.64334369]\n",
      "[ 1.61753035] [ 1.65108287]\n",
      "[ 1.64234662] [ 1.65718472]\n",
      "[ 1.66313541] [ 1.66192365]\n",
      "[ 1.68056893] [ 1.66552842]\n",
      "[ 1.69520712] [ 1.66818941]\n",
      "[ 1.70751655] [ 1.67006528]\n",
      "[ 1.71788585] [ 1.67128813]\n",
      "[ 1.72663856] [ 1.6719681]\n",
      "[ 1.73404431] [ 1.67219687]\n",
      "[ 1.74032784] [ 1.67205071]\n",
      "[ 1.74567616] [ 1.67159331]\n",
      "[ 1.75024509] [ 1.67087758]\n",
      "[ 1.75416446] [ 1.66994774]\n",
      "[ 1.75754237] [ 1.66884053]\n",
      "[ 1.76046896] [ 1.66758657]\n",
      "[ 1.76301932] [ 1.66621137]\n",
      "[ 1.76525581] [ 1.66473615]\n",
      "[ 1.76723063] [ 1.66317868]\n",
      "[ 1.76898706] [ 1.66155362]\n",
      "[ 1.77056134] [ 1.65987325]\n",
      "[ 1.7719835] [ 1.65814769]\n",
      "[ 1.77327859] [ 1.65638554]\n",
      "[ 1.77446747] [ 1.65459394]\n",
      "[ 1.77556765] [ 1.65277874]\n",
      "[ 1.77659357] [ 1.65094483]\n",
      "[ 1.77755725] [ 1.64909625]\n",
      "[ 1.77846885] [ 1.64723647]\n",
      "[ 1.77933669] [ 1.64536834]\n",
      "[ 1.78016782] [ 1.64349413]\n",
      "[ 1.78096795] [ 1.64161587]\n",
      "[ 1.78174198] [ 1.6397351]\n",
      "[ 1.78249395] [ 1.63785326]\n",
      "[ 1.78322721] [ 1.63597155]\n",
      "[ 1.78394449] [ 1.63409078]\n",
      "[ 1.7846483] [ 1.63221169]\n",
      "[ 1.78534043] [ 1.63033509]\n",
      "[ 1.78602254] [ 1.62846136]\n",
      "[ 1.78669608] [ 1.62659097]\n",
      "[ 1.7873621] [ 1.62472439]\n",
      "[ 1.78802156] [ 1.62286174]\n",
      "[ 1.78867519] [ 1.62100339]\n",
      "[ 1.78932369] [ 1.61914957]\n",
      "[ 1.78996766] [ 1.61730039]\n",
      "[ 1.79060745] [ 1.61545599]\n",
      "[ 1.79124355] [ 1.61361647]\n",
      "[ 1.7918762] [ 1.61178195]\n",
      "[ 1.79250562] [ 1.60995245]\n",
      "[ 1.79313219] [ 1.60812807]\n",
      "[ 1.79375601] [ 1.60630894]\n",
      "[ 1.79437721] [ 1.60449493]\n",
      "[ 1.7949959] [ 1.60268617]\n",
      "[ 1.79561222] [ 1.60088265]\n",
      "[ 1.79622626] [ 1.59908438]\n",
      "[ 1.79683816] [ 1.59729135]\n",
      "[ 1.79744792] [ 1.59550357]\n",
      "[ 1.79805553] [ 1.59372115]\n",
      "[ 1.79866111] [ 1.59194398]\n",
      "[ 1.79926479] [ 1.59017205]\n",
      "[ 1.79986644] [ 1.58840537]\n",
      "[ 1.80046618] [ 1.58664393]\n",
      "[ 1.80106401] [ 1.58488774]\n",
      "[ 1.80166006] [ 1.5831368]\n",
      "[ 1.8022542] [ 1.5813911]\n",
      "[ 1.80284655] [ 1.57965052]\n",
      "[ 1.80343699] [ 1.57791519]\n",
      "[ 1.80402565] [ 1.57618499]\n",
      "[ 1.80461252] [ 1.57446003]\n",
      "[ 1.8051976] [ 1.5727402]\n",
      "[ 1.80578101] [ 1.57102549]\n",
      "[ 1.80636263] [ 1.56931591]\n",
      "[ 1.80694246] [ 1.56761146]\n",
      "[ 1.80752051] [ 1.56591213]\n",
      "[ 1.80809689] [ 1.56421781]\n",
      "[ 1.80867147] [ 1.56252861]\n",
      "[ 1.80924428] [ 1.56084442]\n",
      "[ 1.80981541] [ 1.55916536]\n",
      "[ 1.81038487] [ 1.5574913]\n",
      "[ 1.81095254] [ 1.55582225]\n",
      "[ 1.81151855] [ 1.55415821]\n",
      "[ 1.81208289] [ 1.55249918]\n",
      "[ 1.81264544] [ 1.55084503]\n",
      "[ 1.81320632] [ 1.54919589]\n",
      "[ 1.81376553] [ 1.54755163]\n",
      "[ 1.81432307] [ 1.54591227]\n",
      "[ 1.81487894] [ 1.54427791]\n",
      "[ 1.81543314] [ 1.54264843]\n",
      "[ 1.8159858] [ 1.54102385]\n",
      "[ 1.81653678] [ 1.53940403]\n",
      "[ 1.8170861] [ 1.53778911]\n",
      "[ 1.81763375] [ 1.53617907]\n",
      "[ 1.81817973] [ 1.53457379]\n",
      "[ 1.81872404] [ 1.53297329]\n",
      "[ 1.8192668] [ 1.53137767]\n",
      "[ 1.81980789] [ 1.52978683]\n",
      "[ 1.82034743] [ 1.52820075]\n",
      "[ 1.8208853] [ 1.52661932]\n",
      "[ 1.8214215] [ 1.52504265]\n",
      "[ 1.82195616] [ 1.52347076]\n",
      "[ 1.82248914] [ 1.52190351]\n",
      "[ 1.82302058] [ 1.52034104]\n",
      "[ 1.82355046] [ 1.51878321]\n",
      "[ 1.82407868] [ 1.51723003]\n",
      "[ 1.82460535] [ 1.51568151]\n",
      "[ 1.82513046] [ 1.51413763]\n",
      "[ 1.82565403] [ 1.5125984]\n",
      "[ 1.82617605] [ 1.51106369]\n",
      "[ 1.8266964] [ 1.50953364]\n",
      "[ 1.82721519] [ 1.50800812]\n",
      "[ 1.82773256] [ 1.50648725]\n",
      "[ 1.82824826] [ 1.50497091]\n",
      "[ 1.82876253] [ 1.5034591]\n",
      "[ 1.82927525] [ 1.50195181]\n",
      "[ 1.82978642] [ 1.50044906]\n",
      "[ 1.83029604] [ 1.49895072]\n",
      "[ 1.83080411] [ 1.49745691]\n",
      "[ 1.83131063] [ 1.49596751]\n",
      "[ 1.83181572] [ 1.49448264]\n",
      "[ 1.83231926] [ 1.49300218]\n",
      "[ 1.83282125] [ 1.49152613]\n",
      "[ 1.83332181] [ 1.49005449]\n",
      "[ 1.83382082] [ 1.48858726]\n",
      "[ 1.83431828] [ 1.48712444]\n",
      "[ 1.83481431] [ 1.48566604]\n",
      "[ 1.83530891] [ 1.48421204]\n",
      "[ 1.83580196] [ 1.48276234]\n",
      "[ 1.83629358] [ 1.48131704]\n",
      "[ 1.83678365] [ 1.47987604]\n",
      "[ 1.83727229] [ 1.47843933]\n",
      "[ 1.83775949] [ 1.47700691]\n",
      "[ 1.83824527] [ 1.47557878]\n",
      "[ 1.8387295] [ 1.47415495]\n",
      "[ 1.8392123] [ 1.4727354]\n",
      "[ 1.83969367] [ 1.47132003]\n",
      "[ 1.8401736] [ 1.46990895]\n",
      "[ 1.84065211] [ 1.46850204]\n",
      "[ 1.84112918] [ 1.46709943]\n",
      "[ 1.84160483] [ 1.46570098]\n",
      "[ 1.84207904] [ 1.46430671]\n",
      "[ 1.84255183] [ 1.46291661]\n",
      "[ 1.84302318] [ 1.46153069]\n",
      "[ 1.8434931] [ 1.46014893]\n",
      "[ 1.84396172] [ 1.45877135]\n",
      "[ 1.8444289] [ 1.45739782]\n",
      "[ 1.84489465] [ 1.45602846]\n",
      "[ 1.84535897] [ 1.45466316]\n",
      "[ 1.84582198] [ 1.45330191]\n",
      "[ 1.84628356] [ 1.45194483]\n",
      "[ 1.84674382] [ 1.4505918]\n",
      "[ 1.84720266] [ 1.44924283]\n",
      "[ 1.84766006] [ 1.44789779]\n",
      "[ 1.84811616] [ 1.44655681]\n",
      "[ 1.84857094] [ 1.44521987]\n",
      "[ 1.8490243] [ 1.44388688]\n",
      "[ 1.84947634] [ 1.44255793]\n",
      "[ 1.84992695] [ 1.44123292]\n",
      "[ 1.85037625] [ 1.43991196]\n",
      "[ 1.85082424] [ 1.43859494]\n",
      "[ 1.85127079] [ 1.43728185]\n",
      "[ 1.85171604] [ 1.43597269]\n",
      "[ 1.85215998] [ 1.43466747]\n",
      "[ 1.8526026] [ 1.43336606]\n",
      "[ 1.85304391] [ 1.43206859]\n",
      "[ 1.85348392] [ 1.43077505]\n",
      "[ 1.85392261] [ 1.42948532]\n",
      "[ 1.85435998] [ 1.42819953]\n",
      "[ 1.85479605] [ 1.42691755]\n",
      "[ 1.85523081] [ 1.42563939]\n",
      "[ 1.85566425] [ 1.42436504]\n",
      "[ 1.85609639] [ 1.42309451]\n",
      "[ 1.85652721] [ 1.42182779]\n",
      "[ 1.85695672] [ 1.42056489]\n",
      "[ 1.85738492] [ 1.4193058]\n",
      "[ 1.85781193] [ 1.41805041]\n",
      "[ 1.85823762] [ 1.41679883]\n",
      "[ 1.85866201] [ 1.41555095]\n",
      "[ 1.8590852] [ 1.41430688]\n",
      "[ 1.85950708] [ 1.41306651]\n",
      "[ 1.85992765] [ 1.41182983]\n",
      "[ 1.86034703] [ 1.41059685]\n",
      "[ 1.8607651] [ 1.40936756]\n",
      "[ 1.86118197] [ 1.40814197]\n",
      "[ 1.86159754] [ 1.40692008]\n",
      "[ 1.86201191] [ 1.40570176]\n",
      "[ 1.86242509] [ 1.40448713]\n",
      "[ 1.86283696] [ 1.40327609]\n",
      "[ 1.86324763] [ 1.40206873]\n",
      "[ 1.863657] [ 1.40086496]\n",
      "[ 1.86406517] [ 1.39966476]\n",
      "[ 1.86447215] [ 1.39846826]\n",
      "[ 1.86487794] [ 1.39727533]\n",
      "[ 1.86528254] [ 1.39608598]\n",
      "[ 1.86568582] [ 1.39490008]\n",
      "[ 1.86608791] [ 1.39371777]\n",
      "[ 1.86648881] [ 1.39253902]\n",
      "[ 1.86688852] [ 1.39136386]\n",
      "[ 1.86728704] [ 1.39019215]\n",
      "[ 1.86768436] [ 1.3890239]\n",
      "[ 1.8680805] [ 1.38785923]\n",
      "[ 1.86847544] [ 1.38669801]\n",
      "[ 1.86886919] [ 1.38554025]\n",
      "[ 1.86926174] [ 1.38438594]\n",
      "[ 1.86965322] [ 1.3832351]\n",
      "[ 1.87004352] [ 1.38208771]\n",
      "[ 1.87043262] [ 1.38094378]\n",
      "[ 1.87082052] [ 1.3798033]\n",
      "[ 1.87120724] [ 1.37866616]\n",
      "[ 1.87159288] [ 1.37753248]\n",
      "[ 1.87197733] [ 1.37640214]\n",
      "[ 1.87236059] [ 1.37527525]\n",
      "[ 1.87274277] [ 1.37415171]\n",
      "[ 1.87312376] [ 1.3730315]\n",
      "[ 1.87350368] [ 1.37191463]\n",
      "[ 1.87388241] [ 1.37080109]\n",
      "[ 1.87425995] [ 1.3696909]\n",
      "[ 1.87463641] [ 1.36858404]\n",
      "[ 1.8750118] [ 1.36748052]\n",
      "[ 1.875386] [ 1.36638033]\n",
      "[ 1.87575912] [ 1.36528337]\n",
      "[ 1.87613106] [ 1.36418974]\n",
      "[ 1.87650192] [ 1.36309934]\n",
      "[ 1.87687171] [ 1.36201227]\n",
      "[ 1.8772403] [ 1.36092842]\n",
      "[ 1.87760782] [ 1.35984778]\n",
      "[ 1.87797427] [ 1.35877049]\n",
      "[ 1.87833965] [ 1.35769641]\n",
      "[ 1.87870383] [ 1.35662556]\n",
      "[ 1.87906694] [ 1.3555578]\n",
      "[ 1.87942898] [ 1.35449326]\n",
      "[ 1.87978995] [ 1.35343194]\n",
      "[ 1.88014984] [ 1.35237384]\n",
      "[ 1.88050866] [ 1.35131884]\n",
      "[ 1.88086641] [ 1.35026705]\n",
      "[ 1.88122308] [ 1.34921837]\n",
      "[ 1.88157868] [ 1.3481729]\n",
      "[ 1.88193321] [ 1.34713054]\n",
      "[ 1.88228667] [ 1.34609127]\n",
      "[ 1.88263905] [ 1.3450551]\n",
      "[ 1.88299048] [ 1.34402204]\n",
      "[ 1.88334084] [ 1.34299207]\n",
      "[ 1.88369012] [ 1.3419652]\n",
      "[ 1.88403833] [ 1.34094143]\n",
      "[ 1.88438547] [ 1.33992064]\n",
      "[ 1.88473165] [ 1.33890295]\n",
      "[ 1.88507676] [ 1.33788836]\n",
      "[ 1.8854208] [ 1.33687675]\n",
      "[ 1.88576388] [ 1.33586812]\n",
      "[ 1.8861059] [ 1.33486259]\n",
      "[ 1.88644683] [ 1.33386004]\n",
      "[ 1.88678682] [ 1.33286047]\n",
      "[ 1.88712573] [ 1.33186388]\n",
      "[ 1.88746369] [ 1.33087027]\n",
      "[ 1.88780057] [ 1.32987964]\n",
      "[ 1.88813651] [ 1.32889199]\n",
      "[ 1.88847148] [ 1.32790732]\n",
      "[ 1.88880539] [ 1.32692564]\n",
      "[ 1.88913834] [ 1.32594681]\n",
      "[ 1.88947022] [ 1.32497096]\n",
      "[ 1.88980114] [ 1.32399797]\n",
      "[ 1.89013112] [ 1.32302797]\n",
      "[ 1.89046001] [ 1.32206082]\n",
      "[ 1.89078796] [ 1.32109666]\n",
      "[ 1.89111495] [ 1.32013535]\n",
      "[ 1.89144099] [ 1.31917691]\n",
      "[ 1.89176595] [ 1.31822133]\n",
      "[ 1.89208996] [ 1.31726861]\n",
      "[ 1.89241302] [ 1.31631875]\n",
      "[ 1.89273512] [ 1.31537175]\n",
      "[ 1.89305627] [ 1.31442761]\n",
      "[ 1.89337647] [ 1.31348622]\n",
      "[ 1.89369571] [ 1.31254768]\n",
      "[ 1.894014] [ 1.31161189]\n",
      "[ 1.89433134] [ 1.31067896]\n",
      "[ 1.89464772] [ 1.30974877]\n",
      "[ 1.89496315] [ 1.30882144]\n",
      "[ 1.89527762] [ 1.30789685]\n",
      "[ 1.89559114] [ 1.30697501]\n",
      "[ 1.89590371] [ 1.3060559]\n",
      "[ 1.89621532] [ 1.30513954]\n",
      "[ 1.89652598] [ 1.30422592]\n",
      "[ 1.8968358] [ 1.30331516]\n",
      "[ 1.89714468] [ 1.30240703]\n",
      "[ 1.89745259] [ 1.30150163]\n",
      "[ 1.89775968] [ 1.30059898]\n",
      "[ 1.89806581] [ 1.29969907]\n",
      "[ 1.89837098] [ 1.29880178]\n",
      "[ 1.8986752] [ 1.29790723]\n",
      "[ 1.89897859] [ 1.29701531]\n",
      "[ 1.89928102] [ 1.29612613]\n",
      "[ 1.89958251] [ 1.29523957]\n",
      "[ 1.89988315] [ 1.29435563]\n",
      "[ 1.90018284] [ 1.29347432]\n",
      "[ 1.9004817] [ 1.29259574]\n",
      "[ 1.9007796] [ 1.29171979]\n",
      "[ 1.90107667] [ 1.29084647]\n",
      "[ 1.90137291] [ 1.28997576]\n",
      "[ 1.90166819] [ 1.28910756]\n",
      "[ 1.90196264] [ 1.28824198]\n",
      "[ 1.90225613] [ 1.28737903]\n",
      "[ 1.90254879] [ 1.28651869]\n",
      "[ 1.9028405] [ 1.28566086]\n",
      "[ 1.90313137] [ 1.28480566]\n",
      "[ 1.9034214] [ 1.28395295]\n",
      "[ 1.9037106] [ 1.28310287]\n",
      "[ 1.90399885] [ 1.28225529]\n",
      "[ 1.90428627] [ 1.28141022]\n",
      "[ 1.90457284] [ 1.28056765]\n",
      "[ 1.90485859] [ 1.2797277]\n",
      "[ 1.90514338] [ 1.27889025]\n",
      "[ 1.90542734] [ 1.27805531]\n",
      "[ 1.90571046] [ 1.27722287]\n",
      "[ 1.90599275] [ 1.27639294]\n",
      "[ 1.9062742] [ 1.27556539]\n",
      "[ 1.90655482] [ 1.27474034]\n",
      "[ 1.9068346] [ 1.27391779]\n",
      "[ 1.90711355] [ 1.27309775]\n",
      "[ 1.90739167] [ 1.2722801]\n",
      "[ 1.90766895] [ 1.27146494]\n",
      "[ 1.90794539] [ 1.27065217]\n",
      "[ 1.90822101] [ 1.26984191]\n",
      "[ 1.90849578] [ 1.26903403]\n",
      "[ 1.90876973] [ 1.26822853]\n",
      "[ 1.90904284] [ 1.26742554]\n",
      "[ 1.90931511] [ 1.26662493]\n",
      "[ 1.90958655] [ 1.2658267]\n",
      "[ 1.90985727] [ 1.26503086]\n",
      "[ 1.91012716] [ 1.2642374]\n",
      "[ 1.91039622] [ 1.26344633]\n",
      "[ 1.91066444] [ 1.26265764]\n",
      "[ 1.91093194] [ 1.26187122]\n",
      "[ 1.91119862] [ 1.26108718]\n",
      "[ 1.91146445] [ 1.26030552]\n",
      "[ 1.91172957] [ 1.25952625]\n",
      "[ 1.91199386] [ 1.25874925]\n",
      "[ 1.91225731] [ 1.25797462]\n",
      "[ 1.91252005] [ 1.25720227]\n",
      "[ 1.91278195] [ 1.25643218]\n",
      "[ 1.91304302] [ 1.25566447]\n",
      "[ 1.91330338] [ 1.25489902]\n",
      "[ 1.91356289] [ 1.25413585]\n",
      "[ 1.9138217] [ 1.25337493]\n",
      "[ 1.91407967] [ 1.25261641]\n",
      "[ 1.91433692] [ 1.25186014]\n",
      "[ 1.91459334] [ 1.25110614]\n",
      "[ 1.91484904] [ 1.25035441]\n",
      "[ 1.91510391] [ 1.24960482]\n",
      "[ 1.91535807] [ 1.2488575]\n",
      "[ 1.91561151] [ 1.24811244]\n",
      "[ 1.91586411] [ 1.24736965]\n",
      "[ 1.916116] [ 1.246629]\n",
      "[ 1.91636717] [ 1.24589062]\n",
      "[ 1.91661751] [ 1.2451545]\n",
      "[ 1.91686714] [ 1.24442053]\n",
      "[ 1.91711605] [ 1.24368882]\n",
      "[ 1.91736424] [ 1.24295926]\n",
      "[ 1.9176116] [ 1.24223185]\n",
      "[ 1.91785824] [ 1.24150658]\n",
      "[ 1.91810417] [ 1.24078357]\n",
      "[ 1.91834939] [ 1.24006271]\n",
      "[ 1.91859388] [ 1.239344]\n",
      "[ 1.91883755] [ 1.23862743]\n",
      "[ 1.9190805] [ 1.23791301]\n",
      "[ 1.91932273] [ 1.23720074]\n",
      "[ 1.91956425] [ 1.23649061]\n",
      "[ 1.91980505] [ 1.23578262]\n",
      "[ 1.92004514] [ 1.23507667]\n",
      "[ 1.92028451] [ 1.23437285]\n",
      "[ 1.92052317] [ 1.23367119]\n",
      "[ 1.92076111] [ 1.23297155]\n",
      "[ 1.92099833] [ 1.23227406]\n",
      "[ 1.92123485] [ 1.23157871]\n",
      "[ 1.92147064] [ 1.23088539]\n",
      "[ 1.92170572] [ 1.23019409]\n",
      "[ 1.92194021] [ 1.22950494]\n",
      "[ 1.92217398] [ 1.22881782]\n",
      "[ 1.92240703] [ 1.22813272]\n",
      "[ 1.92263937] [ 1.22744977]\n",
      "[ 1.92287099] [ 1.22676885]\n",
      "[ 1.9231019] [ 1.22608995]\n",
      "[ 1.9233321] [ 1.22541308]\n",
      "[ 1.92356169] [ 1.22473824]\n",
      "[ 1.92379057] [ 1.22406542]\n",
      "[ 1.92401874] [ 1.22339463]\n",
      "[ 1.92424619] [ 1.22272575]\n",
      "[ 1.92447293] [ 1.22205889]\n",
      "[ 1.92469907] [ 1.22139406]\n",
      "[ 1.92492449] [ 1.22073126]\n",
      "[ 1.9251492] [ 1.22007036]\n",
      "[ 1.92537332] [ 1.21941149]\n",
      "[ 1.92559671] [ 1.21875465]\n",
      "[ 1.92581952] [ 1.21809971]\n",
      "[ 1.9260416] [ 1.21744668]\n",
      "[ 1.92626297] [ 1.21679568]\n",
      "[ 1.92648375] [ 1.21614659]\n",
      "[ 1.92670381] [ 1.21549952]\n",
      "[ 1.92692327] [ 1.21485436]\n",
      "[ 1.92714202] [ 1.21421111]\n",
      "[ 1.92736018] [ 1.21356976]\n",
      "[ 1.92757761] [ 1.21293032]\n",
      "[ 1.92779446] [ 1.21229279]\n",
      "[ 1.9280107] [ 1.21165717]\n",
      "[ 1.92822623] [ 1.21102345]\n",
      "[ 1.92844117] [ 1.21039164]\n",
      "[ 1.92865539] [ 1.20976174]\n",
      "[ 1.92886901] [ 1.20913374]\n",
      "[ 1.92908192] [ 1.20850766]\n",
      "[ 1.92929423] [ 1.20788336]\n",
      "[ 1.92950594] [ 1.20726097]\n",
      "[ 1.92971706] [ 1.20664048]\n",
      "[ 1.92992747] [ 1.20602179]\n",
      "[ 1.93013728] [ 1.205405]\n",
      "[ 1.93034649] [ 1.20479]\n",
      "[ 1.93055499] [ 1.2041769]\n",
      "[ 1.93076289] [ 1.2035656]\n",
      "[ 1.93097019] [ 1.2029562]\n",
      "[ 1.9311769] [ 1.20234859]\n",
      "[ 1.93138289] [ 1.20174277]\n",
      "[ 1.93158829] [ 1.20113873]\n",
      "[ 1.93179309] [ 1.20053649]\n",
      "[ 1.9319973] [ 1.19993615]\n",
      "[ 1.93220091] [ 1.1993376]\n",
      "[ 1.93240392] [ 1.19874084]\n",
      "[ 1.93260634] [ 1.19814587]\n",
      "[ 1.93280804] [ 1.19755268]\n",
      "[ 1.93300915] [ 1.19696116]\n",
      "[ 1.93320966] [ 1.19637144]\n",
      "[ 1.93340969] [ 1.1957835]\n",
      "[ 1.93360901] [ 1.19519734]\n",
      "[ 1.93380785] [ 1.19461298]\n",
      "[ 1.93400598] [ 1.19403028]\n",
      "[ 1.93420362] [ 1.19344938]\n",
      "[ 1.93440056] [ 1.19287026]\n",
      "[ 1.93459702] [ 1.19229281]\n",
      "[ 1.93479288] [ 1.19171715]\n",
      "[ 1.93498802] [ 1.19114316]\n",
      "[ 1.93518269] [ 1.19057095]\n",
      "[ 1.93537676] [ 1.19000041]\n",
      "[ 1.93557024] [ 1.18943155]\n",
      "[ 1.93576312] [ 1.18886435]\n",
      "[ 1.93595541] [ 1.18829894]\n",
      "[ 1.93614709] [ 1.1877352]\n",
      "[ 1.93633831] [ 1.18717313]\n",
      "[ 1.93652892] [ 1.18661273]\n",
      "[ 1.93671894] [ 1.18605399]\n",
      "[ 1.93690836] [ 1.18549693]\n",
      "[ 1.93709731] [ 1.18494153]\n",
      "[ 1.93728566] [ 1.1843878]\n",
      "[ 1.93747342] [ 1.18383574]\n",
      "[ 1.93766057] [ 1.18328536]\n",
      "[ 1.93784726] [ 1.18273664]\n",
      "[ 1.93803334] [ 1.18218958]\n",
      "[ 1.93821883] [ 1.18164408]\n",
      "[ 1.93840384] [ 1.18110025]\n",
      "[ 1.93858826] [ 1.18055809]\n",
      "[ 1.93877208] [ 1.18001747]\n",
      "[ 1.93895543] [ 1.17947853]\n",
      "[ 1.93913817] [ 1.17894113]\n",
      "[ 1.93932045] [ 1.1784054]\n",
      "[ 1.93950212] [ 1.17787123]\n",
      "[ 1.9396832] [ 1.17733872]\n",
      "[ 1.9398638] [ 1.17680776]\n",
      "[ 1.94004381] [ 1.17627847]\n",
      "[ 1.94022334] [ 1.17575073]\n",
      "[ 1.94040227] [ 1.17522454]\n",
      "[ 1.94058073] [ 1.1746999]\n",
      "[ 1.94075859] [ 1.17417681]\n",
      "[ 1.94093597] [ 1.17365539]\n",
      "[ 1.94111276] [ 1.17313552]\n",
      "[ 1.94128907] [ 1.1726172]\n",
      "[ 1.94146478] [ 1.17210042]\n",
      "[ 1.94164002] [ 1.1715852]\n",
      "[ 1.94181478] [ 1.17107153]\n",
      "[ 1.94198895] [ 1.17055941]\n",
      "[ 1.94216263] [ 1.17004871]\n",
      "[ 1.94233584] [ 1.16953957]\n",
      "[ 1.94250846] [ 1.16903198]\n",
      "[ 1.9426806] [ 1.16852593]\n",
      "[ 1.94285226] [ 1.16802144]\n",
      "[ 1.94302332] [ 1.16751838]\n",
      "[ 1.94319391] [ 1.16701686]\n",
      "[ 1.94336402] [ 1.16651678]\n",
      "[ 1.94353354] [ 1.16601825]\n",
      "[ 1.94370258] [ 1.16552114]\n",
      "[ 1.94387114] [ 1.16502559]\n",
      "[ 1.94403923] [ 1.16453147]\n",
      "[ 1.94420683] [ 1.1640389]\n",
      "[ 1.94437385] [ 1.16354775]\n",
      "[ 1.94454038] [ 1.16305816]\n",
      "[ 1.94470644] [ 1.16257]\n",
      "[ 1.94487202] [ 1.16208327]\n",
      "[ 1.94503701] [ 1.16159797]\n",
      "[ 1.94520152] [ 1.16111422]\n",
      "[ 1.94536555] [ 1.1606319]\n",
      "[ 1.9455291] [ 1.160151]\n",
      "[ 1.94569218] [ 1.15967155]\n",
      "[ 1.94585478] [ 1.15919352]\n",
      "[ 1.94601691] [ 1.15871692]\n",
      "[ 1.94617856] [ 1.15824175]\n",
      "[ 1.94633973] [ 1.15776801]\n",
      "[ 1.94650042] [ 1.1572957]\n",
      "[ 1.94666052] [ 1.15682483]\n",
      "[ 1.94682014] [ 1.15635526]\n",
      "[ 1.9469794] [ 1.15588713]\n",
      "[ 1.94713819] [ 1.15542042]\n",
      "[ 1.94729638] [ 1.15495515]\n",
      "[ 1.94745421] [ 1.15449119]\n",
      "[ 1.94761157] [ 1.15402865]\n",
      "[ 1.94776845] [ 1.15356755]\n",
      "[ 1.94792485] [ 1.15310776]\n",
      "[ 1.94808078] [ 1.1526494]\n",
      "[ 1.94823623] [ 1.15219235]\n",
      "[ 1.9483912] [ 1.15173674]\n",
      "[ 1.94854569] [ 1.15128243]\n",
      "[ 1.94869971] [ 1.15082955]\n",
      "[ 1.94885325] [ 1.15037799]\n",
      "[ 1.94900632] [ 1.14992774]\n",
      "[ 1.94915903] [ 1.14947891]\n",
      "[ 1.94931126] [ 1.1490314]\n",
      "[ 1.94946301] [ 1.1485852]\n",
      "[ 1.94961429] [ 1.14814031]\n",
      "[ 1.94976509] [ 1.14769673]\n",
      "[ 1.94991553] [ 1.14725459]\n",
      "[ 1.95006549] [ 1.14681375]\n",
      "[ 1.95021498] [ 1.14637423]\n",
      "[ 1.95036399] [ 1.14593601]\n",
      "[ 1.95051265] [ 1.14549911]\n",
      "[ 1.95066082] [ 1.14506352]\n",
      "[ 1.95080853] [ 1.14462924]\n",
      "[ 1.95095575] [ 1.14419627]\n",
      "[ 1.95110261] [ 1.14376462]\n",
      "[ 1.951249] [ 1.14333415]\n",
      "[ 1.95139492] [ 1.142905]\n",
      "[ 1.95154047] [ 1.14247715]\n",
      "[ 1.95168555] [ 1.14205062]\n",
      "[ 1.95183015] [ 1.14162529]\n",
      "[ 1.95197439] [ 1.14120126]\n",
      "[ 1.95211816] [ 1.14077854]\n",
      "[ 1.95226145] [ 1.14035702]\n",
      "[ 1.95240438] [ 1.1399368]\n",
      "[ 1.95254683] [ 1.1395179]\n",
      "[ 1.95268893] [ 1.13910019]\n",
      "[ 1.95283055] [ 1.1386838]\n",
      "[ 1.95297182] [ 1.13826859]\n",
      "[ 1.9531126] [ 1.13785458]\n",
      "[ 1.95325303] [ 1.13744187]\n",
      "[ 1.95339298] [ 1.13703036]\n",
      "[ 1.95353246] [ 1.13662004]\n",
      "[ 1.95367157] [ 1.13621104]\n",
      "[ 1.95381033] [ 1.13580322]\n",
      "[ 1.95394862] [ 1.1353966]\n",
      "[ 1.95408654] [ 1.13499129]\n",
      "[ 1.95422399] [ 1.13458717]\n",
      "[ 1.95436108] [ 1.13418424]\n",
      "[ 1.95449769] [ 1.13378251]\n",
      "[ 1.95463395] [ 1.13338196]\n",
      "[ 1.95476973] [ 1.13298261]\n",
      "[ 1.95490515] [ 1.13258445]\n",
      "[ 1.95504022] [ 1.13218749]\n",
      "[ 1.9551748] [ 1.13179171]\n",
      "[ 1.95530903] [ 1.13139713]\n",
      "[ 1.95544279] [ 1.13100374]\n",
      "[ 1.95557618] [ 1.13061154]\n",
      "[ 1.95570922] [ 1.13022053]\n",
      "[ 1.95584178] [ 1.12983072]\n",
      "[ 1.95597398] [ 1.12944198]\n",
      "[ 1.95610583] [ 1.12905443]\n",
      "[ 1.9562372] [ 1.12866807]\n",
      "[ 1.95636821] [ 1.1282829]\n",
      "[ 1.95649886] [ 1.12789881]\n",
      "[ 1.95662904] [ 1.12751591]\n",
      "[ 1.95675886] [ 1.12713408]\n",
      "[ 1.95688832] [ 1.12675345]\n",
      "[ 1.95701742] [ 1.12637401]\n",
      "[ 1.95714605] [ 1.12599564]\n",
      "[ 1.95727432] [ 1.12561846]\n",
      "[ 1.95740223] [ 1.12524235]\n",
      "[ 1.95752978] [ 1.12486744]\n",
      "[ 1.95765698] [ 1.1244936]\n",
      "[ 1.9577837] [ 1.12412083]\n",
      "[ 1.95791006] [ 1.12374926]\n",
      "[ 1.95803607] [ 1.12337875]\n",
      "[ 1.95816171] [ 1.12300932]\n",
      "[ 1.958287] [ 1.12264109]\n",
      "[ 1.95841193] [ 1.12227392]\n",
      "[ 1.95853651] [ 1.12190783]\n",
      "[ 1.9586606] [ 1.12154281]\n",
      "[ 1.95878434] [ 1.12117887]\n",
      "[ 1.95890772] [ 1.12081611]\n",
      "[ 1.95903075] [ 1.12045443]\n",
      "[ 1.95915341] [ 1.12009382]\n",
      "[ 1.95927572] [ 1.11973429]\n",
      "[ 1.95939767] [ 1.11937582]\n",
      "[ 1.95951927] [ 1.11901844]\n",
      "[ 1.9596405] [ 1.11866212]\n",
      "[ 1.95976138] [ 1.11830688]\n",
      "[ 1.95988178] [ 1.1179527]\n",
      "[ 1.96000183] [ 1.11759961]\n",
      "[ 1.96012151] [ 1.11724758]\n",
      "[ 1.96024096] [ 1.11689651]\n",
      "[ 1.96036005] [ 1.11654651]\n",
      "[ 1.96047866] [ 1.11619759]\n",
      "[ 1.96059692] [ 1.11584973]\n",
      "[ 1.96071494] [ 1.11550283]\n",
      "[ 1.9608326] [ 1.11515701]\n",
      "[ 1.9609499] [ 1.11481225]\n",
      "[ 1.96106684] [ 1.11446857]\n",
      "[ 1.96118343] [ 1.11412585]\n",
      "[ 1.96129966] [ 1.11378419]\n",
      "[ 1.96141553] [ 1.11344349]\n",
      "[ 1.96153104] [ 1.11310387]\n",
      "[ 1.9616462] [ 1.11276519]\n",
      "[ 1.961761] [ 1.11242759]\n",
      "[ 1.96187544] [ 1.11209095]\n",
      "[ 1.96198952] [ 1.11175537]\n",
      "[ 1.96210337] [ 1.11142075]\n",
      "[ 1.96221685] [ 1.1110872]\n",
      "[ 1.96232998] [ 1.11075461]\n",
      "[ 1.96244276] [ 1.11042297]\n",
      "[ 1.96255517] [ 1.1100924]\n",
      "[ 1.96266723] [ 1.10976279]\n",
      "[ 1.96277905] [ 1.10943413]\n",
      "[ 1.96289051] [ 1.10910654]\n",
      "[ 1.96300161] [ 1.10877991]\n",
      "[ 1.96311235] [ 1.10845423]\n",
      "[ 1.96322274] [ 1.1081295]\n",
      "[ 1.96333289] [ 1.10780573]\n",
      "[ 1.96344268] [ 1.10748291]\n",
      "[ 1.96355212] [ 1.10716116]\n",
      "[ 1.96366119] [ 1.10684037]\n",
      "[ 1.96377003] [ 1.10652053]\n",
      "[ 1.96387851] [ 1.10620165]\n",
      "[ 1.96398664] [ 1.10588372]\n",
      "[ 1.9640944] [ 1.10556674]\n",
      "[ 1.96420193] [ 1.10525072]\n",
      "[ 1.9643091] [ 1.10493565]\n",
      "[ 1.96441591] [ 1.10462153]\n",
      "[ 1.96452248] [ 1.10430825]\n",
      "[ 1.9646287] [ 1.10399592]\n",
      "[ 1.96473455] [ 1.10368454]\n",
      "[ 1.96484017] [ 1.10337412]\n",
      "[ 1.96494544] [ 1.10306466]\n",
      "[ 1.96505034] [ 1.10275614]\n",
      "[ 1.96515501] [ 1.10244846]\n",
      "[ 1.96525931] [ 1.10214174]\n",
      "[ 1.96536338] [ 1.10183597]\n",
      "[ 1.9654671] [ 1.10153103]\n",
      "[ 1.96557045] [ 1.10122705]\n",
      "[ 1.96567357] [ 1.10092402]\n",
      "[ 1.96577632] [ 1.10062182]\n",
      "[ 1.96587884] [ 1.10032058]\n",
      "[ 1.96598101] [ 1.10002017]\n",
      "[ 1.96608281] [ 1.09972072]\n",
      "[ 1.96618438] [ 1.09942222]\n",
      "[ 1.96628559] [ 1.09912455]\n",
      "[ 1.96638656] [ 1.09882784]\n",
      "[ 1.96648717] [ 1.09853196]\n",
      "[ 1.96658754] [ 1.09823692]\n",
      "[ 1.96668756] [ 1.09794283]\n",
      "[ 1.96678734] [ 1.09764957]\n",
      "[ 1.96688676] [ 1.09735727]\n",
      "[ 1.96698582] [ 1.09706581]\n",
      "[ 1.96708465] [ 1.09677517]\n",
      "[ 1.96718323] [ 1.0964855]\n",
      "[ 1.96728146] [ 1.09619665]\n",
      "[ 1.96737945] [ 1.09590864]\n",
      "[ 1.96747708] [ 1.09562147]\n",
      "[ 1.96757448] [ 1.09533513]\n",
      "[ 1.96767151] [ 1.09504974]\n",
      "[ 1.96776831] [ 1.09476519]\n",
      "[ 1.96786475] [ 1.09448147]\n",
      "[ 1.96796095] [ 1.09419858]\n",
      "[ 1.96805692] [ 1.09391654]\n",
      "[ 1.96815252] [ 1.09363532]\n",
      "[ 1.96824789] [ 1.09335494]\n",
      "[ 1.9683429] [ 1.09307539]\n",
      "[ 1.96843767] [ 1.09279668]\n",
      "[ 1.9685322] [ 1.09251881]\n",
      "[ 1.96862638] [ 1.09224176]\n",
      "[ 1.96872032] [ 1.09196556]\n",
      "[ 1.96881402] [ 1.09169018]\n",
      "[ 1.96890736] [ 1.09141564]\n",
      "[ 1.96900046] [ 1.09114194]\n",
      "[ 1.96909332] [ 1.09086907]\n",
      "[ 1.96918583] [ 1.09059703]\n",
      "[ 1.9692781] [ 1.09032583]\n",
      "[ 1.96937013] [ 1.09005547]\n",
      "[ 1.9694618] [ 1.08978581]\n",
      "[ 1.96955323] [ 1.089517]\n",
      "[ 1.96964443] [ 1.08924901]\n",
      "[ 1.96973526] [ 1.08898187]\n",
      "[ 1.96982586] [ 1.08871543]\n",
      "[ 1.96991622] [ 1.08844984]\n",
      "[ 1.97000635] [ 1.08818507]\n",
      "[ 1.97009611] [ 1.08792102]\n",
      "[ 1.97018564] [ 1.08765781]\n",
      "[ 1.97027493] [ 1.08739543]\n",
      "[ 1.97036386] [ 1.08713377]\n",
      "[ 1.97045255] [ 1.08687294]\n",
      "[ 1.970541] [ 1.08661282]\n",
      "[ 1.97062922] [ 1.08635354]\n",
      "[ 1.97071719] [ 1.08609498]\n",
      "[ 1.97080493] [ 1.08583724]\n",
      "[ 1.97089231] [ 1.08558023]\n",
      "[ 1.97097945] [ 1.08532405]\n",
      "[ 1.97106636] [ 1.08506858]\n",
      "[ 1.97115302] [ 1.08481395]\n",
      "[ 1.97123933] [ 1.08456004]\n",
      "[ 1.9713254] [ 1.08430684]\n",
      "[ 1.97141123] [ 1.08405447]\n",
      "[ 1.97149682] [ 1.08380282]\n",
      "[ 1.97158217] [ 1.08355188]\n",
      "[ 1.97166729] [ 1.08330178]\n",
      "[ 1.97175217] [ 1.0830524]\n",
      "[ 1.97183669] [ 1.08280373]\n",
      "[ 1.97192097] [ 1.08255577]\n",
      "[ 1.97200501] [ 1.08230865]\n",
      "[ 1.97208881] [ 1.08206224]\n",
      "[ 1.97217238] [ 1.08181655]\n",
      "[ 1.97225571] [ 1.08157158]\n",
      "[ 1.9723388] [ 1.08132732]\n",
      "[ 1.97242165] [ 1.08108377]\n",
      "[ 1.97250426] [ 1.08084106]\n",
      "[ 1.97258663] [ 1.08059907]\n",
      "[ 1.97266865] [ 1.08035779]\n",
      "[ 1.97275043] [ 1.08011723]\n",
      "[ 1.97283196] [ 1.07987738]\n",
      "[ 1.97291327] [ 1.07963824]\n",
      "[ 1.97299433] [ 1.07939982]\n",
      "[ 1.97307515] [ 1.07916212]\n",
      "[ 1.97315574] [ 1.07892513]\n",
      "[ 1.97323608] [ 1.07868886]\n",
      "[ 1.97331619] [ 1.0784533]\n",
      "[ 1.97339606] [ 1.07821846]\n",
      "[ 1.97347569] [ 1.07798433]\n",
      "[ 1.97355509] [ 1.0777508]\n",
      "[ 1.97363424] [ 1.07751799]\n",
      "[ 1.97371316] [ 1.07728589]\n",
      "[ 1.97379184] [ 1.0770545]\n",
      "[ 1.9738704] [ 1.07682383]\n",
      "[ 1.9739486] [ 1.07659388]\n",
      "[ 1.97402656] [ 1.07636452]\n",
      "[ 1.97410429] [ 1.07613587]\n",
      "[ 1.97418189] [ 1.07590795]\n",
      "[ 1.97425926] [ 1.07568073]\n",
      "[ 1.97433639] [ 1.07545412]\n",
      "[ 1.97441328] [ 1.07522821]\n",
      "[ 1.97448993] [ 1.07500303]\n",
      "[ 1.97456634] [ 1.07477844]\n",
      "[ 1.97464252] [ 1.07455456]\n",
      "[ 1.97471845] [ 1.0743314]\n",
      "[ 1.97479415] [ 1.07410884]\n",
      "[ 1.97486961] [ 1.07388699]\n",
      "[ 1.97494483] [ 1.07366574]\n",
      "[ 1.97501981] [ 1.0734452]\n",
      "[ 1.97509456] [ 1.07322526]\n",
      "[ 1.97516906] [ 1.07300603]\n",
      "[ 1.97524345] [ 1.0727874]\n",
      "[ 1.9753176] [ 1.07256949]\n",
      "[ 1.97539151] [ 1.07235217]\n",
      "[ 1.97546518] [ 1.07213557]\n",
      "[ 1.97553861] [ 1.07191956]\n",
      "[ 1.97561181] [ 1.07170427]\n",
      "[ 1.97568476] [ 1.07148957]\n",
      "[ 1.9757576] [ 1.07127559]\n",
      "[ 1.9758302] [ 1.07106221]\n",
      "[ 1.97590256] [ 1.07084942]\n",
      "[ 1.97597468] [ 1.07063735]\n",
      "[ 1.97604656] [ 1.07042587]\n",
      "[ 1.97611833] [ 1.07021499]\n",
      "[ 1.97618985] [ 1.07000482]\n",
      "[ 1.97626114] [ 1.06979525]\n",
      "[ 1.97633219] [ 1.06958628]\n",
      "[ 1.976403] [ 1.0693779]\n",
      "[ 1.97647369] [ 1.06917024]\n",
      "[ 1.97654414] [ 1.06896317]\n",
      "[ 1.97661436] [ 1.0687567]\n",
      "[ 1.97668433] [ 1.06855083]\n",
      "[ 1.97675419] [ 1.06834555]\n",
      "[ 1.97682381] [ 1.06814098]\n",
      "[ 1.97689319] [ 1.06793702]\n",
      "[ 1.97696233] [ 1.06773365]\n",
      "[ 1.97703123] [ 1.06753087]\n",
      "[ 1.97710001] [ 1.06732869]\n",
      "[ 1.97716856] [ 1.06712711]\n",
      "[ 1.97723687] [ 1.06692612]\n",
      "[ 1.97730505] [ 1.06672573]\n",
      "[ 1.977373] [ 1.06652594]\n",
      "[ 1.97744071] [ 1.06632674]\n",
      "[ 1.97750831] [ 1.06612813]\n",
      "[ 1.97757566] [ 1.06593013]\n",
      "[ 1.97764277] [ 1.06573272]\n",
      "[ 1.97770977] [ 1.0655359]\n",
      "[ 1.97777653] [ 1.06533968]\n",
      "[ 1.97784305] [ 1.06514406]\n",
      "[ 1.97790933] [ 1.06494904]\n",
      "[ 1.97797549] [ 1.06475461]\n",
      "[ 1.97804141] [ 1.06456077]\n",
      "[ 1.97810721] [ 1.06436753]\n",
      "[ 1.97817278] [ 1.06417477]\n",
      "[ 1.97823811] [ 1.06398261]\n",
      "[ 1.97830331] [ 1.06379104]\n",
      "[ 1.97836828] [ 1.06360006]\n",
      "[ 1.97843301] [ 1.06340969]\n",
      "[ 1.97849762] [ 1.06321979]\n",
      "[ 1.978562] [ 1.06303048]\n",
      "[ 1.97862613] [ 1.06284177]\n",
      "[ 1.97869015] [ 1.06265366]\n",
      "[ 1.97875392] [ 1.06246603]\n",
      "[ 1.97881758] [ 1.06227899]\n",
      "[ 1.978881] [ 1.06209254]\n",
      "[ 1.97894418] [ 1.0619067]\n",
      "[ 1.97900724] [ 1.06172132]\n",
      "[ 1.97907007] [ 1.06153655]\n",
      "[ 1.97913277] [ 1.06135237]\n",
      "[ 1.97919524] [ 1.06116867]\n",
      "[ 1.97925758] [ 1.06098557]\n",
      "[ 1.97931969] [ 1.06080294]\n",
      "[ 1.97938156] [ 1.0606209]\n",
      "[ 1.97944331] [ 1.06043935]\n",
      "[ 1.97950482] [ 1.06025839]\n",
      "[ 1.97956622] [ 1.06007802]\n",
      "[ 1.97962737] [ 1.05989814]\n",
      "[ 1.97968841] [ 1.05971885]\n",
      "[ 1.9797492] [ 1.05954003]\n",
      "[ 1.97980988] [ 1.05936182]\n",
      "[ 1.97987032] [ 1.05918407]\n",
      "[ 1.97993052] [ 1.05900693]\n",
      "[ 1.9799906] [ 1.05883026]\n",
      "[ 1.98005056] [ 1.05865407]\n",
      "[ 1.98011029] [ 1.05847847]\n",
      "[ 1.98016977] [ 1.05830336]\n",
      "[ 1.98022914] [ 1.05812883]\n",
      "[ 1.98028827] [ 1.05795479]\n",
      "[ 1.98034728] [ 1.05778134]\n",
      "[ 1.98040617] [ 1.05760837]\n",
      "[ 1.98046482] [ 1.05743587]\n",
      "[ 1.98052335] [ 1.05726397]\n",
      "[ 1.98058164] [ 1.05709255]\n",
      "[ 1.98063982] [ 1.0569216]\n",
      "[ 1.98069775] [ 1.05675113]\n",
      "[ 1.98075557] [ 1.05658126]\n",
      "[ 1.98081315] [ 1.05641186]\n",
      "[ 1.9808706] [ 1.05624294]\n",
      "[ 1.98092782] [ 1.0560745]\n",
      "[ 1.98098493] [ 1.05590665]\n",
      "[ 1.98104191] [ 1.05573928]\n",
      "[ 1.98109865] [ 1.05557239]\n",
      "[ 1.98115528] [ 1.05540597]\n",
      "[ 1.98121166] [ 1.05524004]\n",
      "[ 1.98126793] [ 1.05507469]\n",
      "[ 1.98132396] [ 1.05490983]\n",
      "[ 1.98137987] [ 1.05474544]\n",
      "[ 1.98143566] [ 1.05458152]\n",
      "[ 1.98149121] [ 1.05441809]\n",
      "[ 1.98154664] [ 1.05425513]\n",
      "[ 1.98160183] [ 1.05409265]\n",
      "[ 1.98165691] [ 1.05393064]\n",
      "[ 1.98171186] [ 1.05376923]\n",
      "[ 1.98176658] [ 1.0536083]\n",
      "[ 1.98182118] [ 1.05344784]\n",
      "[ 1.98187566] [ 1.05328786]\n",
      "[ 1.9819299] [ 1.05312836]\n",
      "[ 1.98198402] [ 1.05296934]\n",
      "[ 1.9820379] [ 1.05281079]\n",
      "[ 1.98209167] [ 1.05265272]\n",
      "[ 1.98214531] [ 1.05249512]\n",
      "[ 1.98219872] [ 1.052338]\n",
      "[ 1.982252] [ 1.05218136]\n",
      "[ 1.98230517] [ 1.05202508]\n",
      "[ 1.9823581] [ 1.05186927]\n",
      "[ 1.98241091] [ 1.05171394]\n",
      "[ 1.9824636] [ 1.05155909]\n",
      "[ 1.98251605] [ 1.05140471]\n",
      "[ 1.98256838] [ 1.05125082]\n",
      "[ 1.9826206] [ 1.05109739]\n",
      "[ 1.98267269] [ 1.05094445]\n",
      "[ 1.98272455] [ 1.05079198]\n",
      "[ 1.98277628] [ 1.05063987]\n",
      "[ 1.9828279] [ 1.05048823]\n",
      "[ 1.98287928] [ 1.05033708]\n",
      "[ 1.98293054] [ 1.0501864]\n",
      "[ 1.98298168] [ 1.05003619]\n",
      "[ 1.98303258] [ 1.04988635]\n",
      "[ 1.98308337] [ 1.04973698]\n",
      "[ 1.98313403] [ 1.04958808]\n",
      "[ 1.98318458] [ 1.04943967]\n",
      "[ 1.98323488] [ 1.04929161]\n",
      "[ 1.98328507] [ 1.04914403]\n",
      "[ 1.98333514] [ 1.04899693]\n",
      "[ 1.98338497] [ 1.04885018]\n",
      "[ 1.98343468] [ 1.04870391]\n",
      "[ 1.98348427] [ 1.04855812]\n",
      "[ 1.98353374] [ 1.04841268]\n",
      "[ 1.98358309] [ 1.04826772]\n",
      "[ 1.98363221] [ 1.04812324]\n",
      "[ 1.9836812] [ 1.04797912]\n",
      "[ 1.98373008] [ 1.04783547]\n",
      "[ 1.98377883] [ 1.0476923]\n",
      "[ 1.98382735] [ 1.04754949]\n",
      "[ 1.98387575] [ 1.04740715]\n",
      "[ 1.98392403] [ 1.04726517]\n",
      "[ 1.98397219] [ 1.04712367]\n",
      "[ 1.98402023] [ 1.04698253]\n",
      "[ 1.98406804] [ 1.04684186]\n",
      "[ 1.98411572] [ 1.04670167]\n",
      "[ 1.98416328] [ 1.04656184]\n",
      "[ 1.98421073] [ 1.04642248]\n",
      "[ 1.98425806] [ 1.04628348]\n",
      "[ 1.98430514] [ 1.04614496]\n",
      "[ 1.98435211] [ 1.0460068]\n",
      "[ 1.98439896] [ 1.04586911]\n",
      "[ 1.98444569] [ 1.04573178]\n",
      "[ 1.98449218] [ 1.04559481]\n",
      "[ 1.98453867] [ 1.04545832]\n",
      "[ 1.98458493] [ 1.04532218]\n",
      "[ 1.98463106] [ 1.04518652]\n",
      "[ 1.98467708] [ 1.04505122]\n",
      "[ 1.98472297] [ 1.04491639]\n",
      "[ 1.98476875] [ 1.04478192]\n",
      "[ 1.98481429] [ 1.04464781]\n",
      "[ 1.9848597] [ 1.04451418]\n",
      "[ 1.984905] [ 1.0443809]\n",
      "[ 1.98495018] [ 1.04424798]\n",
      "[ 1.98499525] [ 1.04411554]\n",
      "[ 1.98504019] [ 1.04398346]\n",
      "[ 1.98508501] [ 1.04385173]\n",
      "[ 1.98512971] [ 1.04372048]\n",
      "[ 1.98517418] [ 1.04358959]\n",
      "[ 1.98521852] [ 1.04345906]\n",
      "[ 1.98526275] [ 1.043329]\n",
      "[ 1.98530686] [ 1.0431993]\n",
      "[ 1.98535085] [ 1.04306996]\n",
      "[ 1.98539472] [ 1.04294097]\n",
      "[ 1.98543847] [ 1.04281247]\n",
      "[ 1.9854821] [ 1.04268432]\n",
      "[ 1.98552561] [ 1.04255652]\n",
      "[ 1.98556888] [ 1.04242909]\n",
      "[ 1.98561203] [ 1.04230201]\n",
      "[ 1.98565519] [ 1.04217541]\n",
      "[ 1.9856981] [ 1.04204917]\n",
      "[ 1.9857409] [ 1.04192328]\n",
      "[ 1.98578358] [ 1.04179776]\n",
      "[ 1.98582613] [ 1.04167259]\n",
      "[ 1.98586857] [ 1.04154778]\n",
      "[ 1.98591089] [ 1.04142344]\n",
      "[ 1.98595309] [ 1.04129946]\n",
      "[ 1.98599517] [ 1.04117584]\n",
      "[ 1.98603714] [ 1.04105258]\n",
      "[ 1.98607898] [ 1.04092968]\n",
      "[ 1.9861207] [ 1.04080713]\n",
      "[ 1.98616219] [ 1.04068494]\n",
      "[ 1.98620367] [ 1.04056311]\n",
      "[ 1.98624492] [ 1.04044163]\n",
      "[ 1.98628616] [ 1.04032052]\n",
      "[ 1.98632717] [ 1.04019976]\n",
      "[ 1.98636806] [ 1.04007936]\n",
      "[ 1.98640883] [ 1.03995931]\n",
      "[ 1.98644948] [ 1.03983963]\n",
      "[ 1.98649001] [ 1.0397203]\n",
      "[ 1.98653054] [ 1.03960145]\n",
      "[ 1.98657084] [ 1.03948283]\n",
      "[ 1.98661101] [ 1.03936458]\n",
      "[ 1.98665118] [ 1.03924668]\n",
      "[ 1.98669124] [ 1.03912914]\n",
      "[ 1.98673105] [ 1.03901196]\n",
      "[ 1.98677075] [ 1.03889513]\n",
      "[ 1.98681033] [ 1.03877866]\n",
      "[ 1.98684978] [ 1.03866255]\n",
      "[ 1.98688924] [ 1.0385468]\n",
      "[ 1.98692846] [ 1.03843141]\n",
      "[ 1.98696768] [ 1.03831637]\n",
      "[ 1.98700666] [ 1.03820169]\n",
      "[ 1.98704553] [ 1.03808737]\n",
      "[ 1.98708439] [ 1.0379734]\n",
      "[ 1.98712301] [ 1.03785968]\n",
      "[ 1.98716152] [ 1.03774631]\n",
      "[ 1.98720002] [ 1.0376333]\n",
      "[ 1.98723841] [ 1.03752065]\n",
      "[ 1.98727667] [ 1.03740835]\n",
      "[ 1.9873147] [ 1.0372963]\n",
      "[ 1.98735273] [ 1.0371846]\n",
      "[ 1.98739064] [ 1.03707325]\n",
      "[ 1.98742843] [ 1.03696227]\n",
      "[ 1.9874661] [ 1.03685164]\n",
      "[ 1.98750365] [ 1.03674126]\n",
      "[ 1.98754108] [ 1.03663123]\n",
      "[ 1.98757839] [ 1.03652155]\n",
      "[ 1.98761559] [ 1.03641224]\n",
      "[ 1.98765266] [ 1.03630316]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    _, w, c = sess.run([train, W, b], feed_dict={X: [1.0,2.0,3.0,4.0], y: [3.0,5.0,7.0,9.0]})\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.98765266], dtype=float32), array([ 1.03630316], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "tf.contrib.learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.contrib.learn is a high-level TensorFlow library that simplifies the mechanics of machine learning, including the following:\n",
    "\n",
    "    -running training loops\n",
    "    -running evaluation loops\n",
    "    -managing data sets\n",
    "    -managing feeding\n",
    "tf.contrib.learn defines many common models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprusatr_3\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_task_type': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8764186d30>, '_save_checkpoints_secs': 600, '_environment': 'local', '_master': '', '_is_chief': True, '_evaluation_master': '', '_tf_random_seed': None}\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/antonio/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmprusatr_3/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.25, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1137.02\n",
      "INFO:tensorflow:loss = 0.0565433, step = 101\n",
      "INFO:tensorflow:global_step/sec: 1203.39\n",
      "INFO:tensorflow:loss = 0.00973714, step = 201\n",
      "INFO:tensorflow:global_step/sec: 1204.81\n",
      "INFO:tensorflow:loss = 0.00196056, step = 301\n",
      "INFO:tensorflow:global_step/sec: 1189.58\n",
      "INFO:tensorflow:loss = 0.000667228, step = 401\n",
      "INFO:tensorflow:global_step/sec: 560.463\n",
      "INFO:tensorflow:loss = 8.75442e-05, step = 501\n",
      "INFO:tensorflow:global_step/sec: 540.626\n",
      "INFO:tensorflow:loss = 2.9348e-05, step = 601\n",
      "INFO:tensorflow:global_step/sec: 945.302\n",
      "INFO:tensorflow:loss = 3.56396e-06, step = 701\n",
      "INFO:tensorflow:global_step/sec: 1370.24\n",
      "INFO:tensorflow:loss = 8.1024e-07, step = 801\n",
      "INFO:tensorflow:global_step/sec: 1485.63\n",
      "INFO:tensorflow:loss = 1.71485e-07, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmprusatr_3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.67794e-08.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/antonio/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-26-17:38:48\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-26-17:38:48\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 3.23022e-08\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 1000, 'loss': 3.2302246e-08}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use `numpy_input_fn`. We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the `fit` method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did. In a real example, we would want\n",
    "# to use a separate validation and testing data set to avoid overfitting.\n",
    "estimator.evaluate(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.contrib.learn does not lock you into its predefined models. Suppose we wanted to create a custom model that is not built into TensorFlow. We can still retain the high level abstraction of data set, feeding, training, etc. of tf.contrib.learn. For illustration, we will show how to implement our own equivalent model to LinearRegressor using our knowledge of the lower level TensorFlow API.\n",
    "\n",
    "To define a custom model that works with tf.contrib.learn, we need to use tf.contrib.learn.Estimator. tf.contrib.learn.LinearRegressor is actually a sub-class of tf.contrib.learn.Estimator. Instead of sub-classing Estimator, we simply provide Estimator a function model_fn that tells tf.contrib.learn how it can evaluate predictions, training steps, and loss. The code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1r1lmplh\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_task_type': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f87643fae10>, '_save_checkpoints_secs': 600, '_environment': 'local', '_master': '', '_is_chief': True, '_evaluation_master': '', '_tf_random_seed': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp1r1lmplh/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.09955812321, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1034.07\n",
      "INFO:tensorflow:loss = 0.00100986192778, step = 101\n",
      "INFO:tensorflow:global_step/sec: 898.54\n",
      "INFO:tensorflow:loss = 1.64997907147e-05, step = 201\n",
      "INFO:tensorflow:global_step/sec: 1032.14\n",
      "INFO:tensorflow:loss = 1.02068591281e-05, step = 301\n",
      "INFO:tensorflow:global_step/sec: 1004.02\n",
      "INFO:tensorflow:loss = 1.287431321e-06, step = 401\n",
      "INFO:tensorflow:global_step/sec: 833.617\n",
      "INFO:tensorflow:loss = 9.8754719022e-08, step = 501\n",
      "INFO:tensorflow:global_step/sec: 819.784\n",
      "INFO:tensorflow:loss = 1.08708637164e-08, step = 601\n",
      "INFO:tensorflow:global_step/sec: 838.383\n",
      "INFO:tensorflow:loss = 1.10237664155e-09, step = 701\n",
      "INFO:tensorflow:global_step/sec: 970.755\n",
      "INFO:tensorflow:loss = 3.83776070704e-11, step = 801\n",
      "INFO:tensorflow:global_step/sec: 1402.98\n",
      "INFO:tensorflow:loss = 6.64119655067e-12, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp1r1lmplh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.69337392186e-13.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-26-20:28:23\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-26-20:28:23\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 4.9103e-13\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'global_step': 1000, 'loss': 4.9103029e-13}\n"
     ]
    }
   ],
   "source": [
    "def model(features, labels, mode):# Build a linear model and predict values\n",
    "    # Declare list of features, we only have one real-valued feature\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                     tf.assign_add(global_step, 1))\n",
    "    # ModelFnOps connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.contrib.learn.ModelFnOps(\n",
    "        mode=mode, predictions=y,\n",
    "        loss=loss,\n",
    "        train_op=train)\n",
    "\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)\n",
    "# define our data set\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x}, y, 4, num_epochs=1000)\n",
    "\n",
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "# evaluate our model\n",
    "print(estimator.evaluate(input_fn=input_fn, steps=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
